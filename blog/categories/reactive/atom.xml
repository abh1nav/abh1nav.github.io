<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: reactive | sqldump]]></title>
  <link href="http://blog.abhinav.ca/blog/categories/reactive/atom.xml" rel="self"/>
  <link href="http://blog.abhinav.ca/"/>
  <updated>2015-02-20T06:39:34-05:00</updated>
  <id>http://blog.abhinav.ca/</id>
  <author>
    <name><![CDATA[Abhinav Ajgaonkar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Scaling with Akka Streams: Fetch 1M Twitter Profiles in less than 5min]]></title>
    <link href="http://blog.abhinav.ca/blog/2015/02/19/scaling-with-akka-streams/"/>
    <updated>2015-02-19T21:15:09-05:00</updated>
    <id>http://blog.abhinav.ca/blog/2015/02/19/scaling-with-akka-streams</id>
    <content type="html"><![CDATA[<p>During these past few weeks, I&rsquo;ve had a chance to play around quite a bit with the soon-to-be-1.0 <a href="http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M3/scala.html">Akka Streams</a> module and I&rsquo;ve been looking for a concrete reason to write about why this is an important milestone for the stream processing ecosystem. It just so happens that this week, we were conducting an experiment related to Twitter follower analysis that required pulling a few million public user profiles of followers of large Twitter accounts and the ability to do so in a relatively short amount of time. I decided to use Akka Streams for this project to see how far I could push it in a real world scenario.</p>

<h2>App Skeleton</h2>

<p>I decided to start with a regular Scala command line app and hardcode the Twitter ID of the person whose followers' profiles we were attempting to retrieve (since this is going to be throwaway code just for the sake of the experiment). The only dependencies were <a href="http://mvnrepository.com/artifact/com.typesafe.akka/akka-actor_2.11/2.3.9">akka-actor</a>, <a href="http://mvnrepository.com/artifact/com.typesafe.akka/akka-stream-experimental_2.11/1.0-M3">akka-stream-experimental</a> and <a href="http://mvnrepository.com/artifact/org.twitter4j/twitter4j-core/4.0.2">twitter4j-core</a>.</p>

<h3>Twitter API Interaction</h3>

<p>We need some way to call the Twitter API primarily for two reasons:</p>

<p>1) Fetch all follower IDs of a given userID<br/>
2) Fetch a user profile given a userID.</p>

<p>Any call made to Twiter&rsquo;s API needs an authenticated <code>twitter4j.Twitter</code> object. Given a set of credentials, a <code>twitter4j.Twitter</code> object is constructed as follows:</p>

<p>```scala
import twitter4j.{Twitter, TwitterFactory}
import twitter4j.auth.AccessToken
import twitter4j.conf.ConfigurationBuilder</p>

<p>object TwitterClient {</p>

<pre><code>// Fill these in with your own credentials
val appKey: String = ""
val appSecret: String = ""
val accessToken: String = ""
val accessTokenSecret: String = ""

def apply(): Twitter = {
    val factory = new TwitterFactory(new ConfigurationBuilder().build())
    val t = factory.getInstance()
    t.setOAuthConsumer(appKey, appSecret)
    t.setOAuthAccessToken(new AccessToken(accessToken, accessTokenSecret))  
    t
}    
</code></pre>

<p>}</p>

<p>```</p>

<h4>Given a user, return all followers</h4>

<p>Using the <code>TwitterClient</code>, we can fetch a user&rsquo;s profile and list of followers with the following <code>TwitterHelpers</code> object:</p>

<p>```scala
object TwitterHelpers {</p>

<pre><code>// Lookup user profiles in batches of 100
def lookupUsers(ids: List[Long]): List[User] = {
  val client = TwitterClient()
  val res = client.lookupUsers(ids.toArray)
  res.toList
}

// Fetch the IDs of a user's followers in batches of 5000
def getFollowers(userId: Long): Try[Set[Long]] = {
  Try({
    val followerIds = mutable.Set[Long]()
    var cursor = -1L
    do {
      val client = TwitterClient()
      val res = client.friendsFollowers().getFollowersIDs(userId, cursor, 5000)
      res.getIDs.toList.foreach(x =&gt; followerIds.add(x))
      if (res.hasNext) {
        cursor = res.getNextCursor
      }
      else {
        cursor = -1 // Exit the loop
      }
    } while (cursor &gt; 0)
    followerIds.toSet
  })
}
</code></pre>

<p>}
```</p>

<h3>Akka Boilerplate</h3>

<p>With the Twitter interactions out of the way, we can create a new command line app using:</p>

<p>```scala
object Main extends App {</p>

<p>  // ActorSystem &amp; thread pools
  implicit val system: ActorSystem = ActorSystem(&ldquo;centaur&rdquo;)
  val executorService: ExecutorService = Executors.newCachedThreadPool()
  val ec: ExecutionContext = ExecutionContext.fromExecutorService(executorService)
  val log: LoggingAdapter = Logging.getLogger(system, Main)
  implicit val materializer = ActorFlowMaterializer()(system)</p>

<p>  // Put Stream code here
  //
  //
}
```</p>

<p>At this point, we have a working app that can be invoked using <code>sbt run</code>. Let&rsquo;s get started on the Akka Streams bit.</p>

<h3>The Pipeline</h3>

<p>```scala
val startTime = System.nanoTime()
val userId = 410939902L // @headinthebox ~12K followers
val output = new ConcurrentLinkedQueue<a href="">String</a>
Console.println(s"Fetching follower profiles for $userId")
Source(() => TwitterHelpers.getFollowers(userId).get.toIterable.iterator)
  .grouped(100)
  .map(x => TwitterHelpers.lookupUsers(x.toList))
  .mapConcat(identity)
  .runForeach(x => output.offer(x.getScreenName))
  .onComplete({</p>

<pre><code>case _ =&gt;
  Console.println(s"Fetched ${output.size()} profiles")
  val endTime = System.nanoTime()
  Console.println(s"Time taken: ${(endTime - startTime)/1000000000.00}s")
  system.shutdown()
  Runtime.getRuntime.exit(0)
</code></pre>

<p>  }) (ec)
```</p>

<p>Breaking down the flow line by line
<code>scala
Source(() =&gt; TwitterHelpers.getFollowers(userId).get.toIterable.iterator)
</code>
turns the <code>Set[Long]</code> of follower IDs into an Akka Streams <code>Source</code>.
<code>scala
.grouped(100) // outputs a stream of Seq[Long]
.map(x =&gt; TwitterHelpers.lookupUsers(x.toList)) // outputs a stream of List[User]
.mapConcat(identity) // flattens the stream of List[User] into a stream of User
</code>
The <code>group</code>, <code>map</code> and <code>mapConcat</code> transform the stream of Longs into a stream of <code>twitter4j.User</code> objects.
<code>scala
.runForeach(x =&gt; output.offer(x.getScreenName))
</code>
And finally, the user objects are piped into a <code>Sink</code> which adds them to our output queue.</p>

<h3>Run 1 &ndash; 12,199 profiles in 108s</h3>

<p>Running this flow takes 108 seconds to retrieve 12,199 user profiles from Twitter.</p>

<p><a href="/images/2015-02-19-Attempt-1.png"><img src="/images/2015-02-19-Attempt-1.png"></a></p>

<h3>Run 2 &ndash; 12,200 profiles in 11s</h3>

<p>Modifying the flow slightly to allow for more concurrency helps bring down the total time taken by a large value. The obvious bottleneck in the flow implementation is the synchronous fetching of user profiles in the stage where User IDs are mapped to User profile objects. Replacing the
<code>scala
.map(x =&gt; TwitterHelpers.lookupUsers(x.toList))
</code>
with
<code>scala
.mapAsyncUnordered[List[User]](x =&gt; Future[List[User]]({ TwitterHelpers.lookupUsers(x.toList) } (ec)))
</code>
reduces the time taken from <strong>108</strong>s to <strong>11</strong>s. <strong>That&rsquo;s almost 10x faster with a single line change!</strong></p>

<p><a href="/images/2015-02-19-Attempt-2.png"><img src="/images/2015-02-19-Attempt-2.png"></a></p>

<p>(It looks like Erik Meijer has gained a follower between our two runs).</p>

<h3>Run 3 &ndash; 1.22M profiles in 256s</h3>

<p><a href="https://twitter.com/netflix">Netflix USA</a> has approximately 1.22M followers. Fetching followers for this account took 256s.</p>

<p><a href="/images/2015-02-19-Attempt-3.png"><img src="/images/2015-02-19-Attempt-3.png"></a></p>

<h3>Run 4 &ndash; 2.88M profiles in 647s</h3>

<p>Twitter co-founder <a href="https://twitter.com/jack">Jack Dorsey</a> has 2.88M followers and the pipeline processed them in 647 seconds.</p>

<p><a href="/images/2015-02-19-Attempt-4.png"><img src="/images/2015-02-19-Attempt-4.png"></a></p>

<p>Since Netflix (1.22M) was processed in 256s and Jack (2.88M) was processed in ~650s, it doesn&rsquo;t look like the pipeline is showing any signs of exhaustion as larger accounts are being processed.</p>

<h3>Final Thoughts</h3>

<p>Before Akka Streams, creating a flow like this would require hand coding each stage as an actor, manually wiring everything up and carefully managing backpressure using a hybrid push/pull system alongwith finely configured timeouts and inbox sizes. Having worked on many such systems at <a href="http://crowdriff.com">CrowdRiff</a>, my experience so far has been mostly positive. Akka delivers exactly what it promises &ndash; an easy way to think about concurrency, excellent performance and a great toolkit to build distributed systems. However, once built, these systems often tend to be very complex and common changes like adding stages to the pipeline or modifying existing stages have to be done very carefully (despite unit tests!). Akka Streams takes this to a whole new level by allowing the user to create arbitrary flows (check out <a href="http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M3/scala/stream-graphs.html">stream graphs</a>) in simple and easy to read manner AND managing the backpressure for you! The large quantity of awesome in this module is certainly appreciated by me and my team &ndash; many thanks to the Akka folks and everyone who contributed to the Reactive Streams project. Happy hAkking!</p>
]]></content>
  </entry>
  
</feed>
